import os
from openai import OpenAI
from dotenv import load_dotenv, find_dotenv

load_dotenv(find_dotenv())
openai_api_key = os.getenv("OPENAI_API_KEY_UNSU")
client = OpenAI(api_key=openai_api_key)

import streamlit as st

# ì œëª©ê³¼ ì´ˆê¸°í™” ë²„íŠ¼ì„ ê°™ì€ ì¤„ì— ë°°ì¹˜
if st.button("ğŸ”„ ì´ˆê¸°í™”", type="secondary"):
    st.session_state.chat_history = []
    if 'response_id' in st.session_state:
        del st.session_state.response_id
    st.rerun()
st.title("í˜„ì§„ê±´ ì‘ê°€ë‹˜ê³¼ì˜ ëŒ€í™”")
st.write("---")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []

# ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ
if 'response_id' in st.session_state:
    for message in st.session_state.chat_history:
        with st.chat_message(message["role"]):
            st.write(message["content"])

# ì§ˆë¬¸ ì…ë ¥ (Streamlitì˜ chat_inputì€ ìë™ìœ¼ë¡œ í˜ì´ì§€ í•˜ë‹¨ì— ê³ ì •ë¨)
prompt = st.chat_input("ë¬¼ì–´ë³´ê³  ì‹¶ì€ ê²ƒì„ ì…ë ¥í•˜ì„¸ìš”!")

if prompt:
    with st.chat_message("user"):
        st.write(prompt)
    st.session_state.chat_history.append({"role": "user", "content": prompt})
    if 'response_id' not in st.session_state:
        with st.spinner("Wait for it..."):
            response = client.responses.create(
                model="gpt-4o-mini",
                instructions="ë‹¹ì‹ ì€ ì†Œì„¤ ìš´ìˆ˜ ì¢‹ì€ ë‚ ì„ ì§‘í•„í•œ í˜„ì§„ê±´ ì‘ê°€ë‹˜ì…ë‹ˆë‹¤.",
                # input=[
                #     {
                #         "role": "user",
                #         "content": [
                #             {
                #                 "type": "input_text",
                #                 "text": "ì•„ë‚´ê°€ ë¨¹ê³  ì‹¶ì–´í•œ ìŒì‹ì´ ë­ì•¼?"
                #             }
                #         ]
                #     }
                # ],
                input=prompt,
                tools=[
                    {
                        "type": "file_search",
                        "vector_store_ids": [
                            "vs_68a6d3e61f648191bfbf3395f226fb02"
                        ]
                    }
                ],
                temperature=1,
                max_output_tokens=2048,
                top_p=1,
                store=True
            )
    else:
        with st.spinner("Wait for it..."):
            response = client.responses.create(
                previous_response_id=st.session_state.response_id,
                model="gpt-4o-mini",
                instructions="ë‹¹ì‹ ì€ ì†Œì„¤ ìš´ìˆ˜ ì¢‹ì€ ë‚ ì„ ì§‘í•„í•œ í˜„ì§„ê±´ ì‘ê°€ë‹˜ì…ë‹ˆë‹¤.",
                input=prompt,
                tools=[
                    {
                        "type": "file_search",
                        "vector_store_ids": ["vs_68a6d3e61f648191bfbf3395f226fb02"]
                    }
                ],
            )

    with st.chat_message("assistant"):
        st.write(response.output_text)
    
    st.session_state.chat_history.append({"role": "assistant", "content": response.output_text})
    st.session_state.response_id = response.id