{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41949418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "model_name = os.getenv(\"LLM_MODEL\") or \"gpt-4o-mini\"\n",
    "model_provider = os.getenv(\"LLM_MODEL_PROVIDER\") or \"openai\"\n",
    "\n",
    "current_dir = Path.cwd()\n",
    "data_dir = current_dir.parent / \"data\"\n",
    "index_dir = current_dir.parent / \"index\"\n",
    "\n",
    "restaurant_faiss = index_dir / \"restaurant-faiss\"\n",
    "restaurant_text = data_dir / \"restaurants.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57dda3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_faiss_index():\n",
    "    loader = TextLoader(str(restaurant_text))\n",
    "    documents = loader.load()\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "    chunks = text_splitter.create_documents(documents)\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-large\",\n",
    "    )\n",
    "\n",
    "    db = FAISS.from_documents(chunks, embeddings)\n",
    "    db.save_local(str(restaurant_faiss))\n",
    "    \n",
    "    print(\"Faiss Index created and saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14196928",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_faiss_index():\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        model=\"text-embedding-3-large\",\n",
    "    )\n",
    "    load_db = FAISS.load_local(\n",
    "        str(restaurant_faiss),\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True,\n",
    "    )\n",
    "\n",
    "    return load_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eab90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1558a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(db, query):\n",
    "    llm = ChatOpenAI(model=model_name)\n",
    "    prompt_template = \"\"\"\n",
    "    당신은 유능한 AI 비서입니다. 주어진 맥락 정보를 바탕으로 사용자의 질문에 정확하고 도움이 되는 답변을 제공해야 합니다.\n",
    "    맥락: {context}\n",
    "    질문: {question}\n",
    "    답변을 작성할 때 다음 지침을 따르세요:\n",
    "    1. 주어진 맥락 정보에 있는 내용만을 사용하여 답변하세요.\n",
    "    2. 맥락 정보에 없는 내용은 답변에 포함하지 마세요.\n",
    "    3. 질문과 관련이 없는 정보는 제외하세요\n",
    "    4. 답변은 간결하고 명확하게 작성하세요.\n",
    "    5. 불확실한 경우, \"주어진 정보로는 정확한 답변을 드릴 수 없습니다.\"라고 답변하세요.\n",
    "    답변: \n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "\n",
    "    qa_chain = (\n",
    "        {\n",
    "            \"context\": db.as_retriever() | format_docs,\n",
    "            \"question\": RunnablePassthrough()\n",
    "        }\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    #result = qa_chain.invoke({\"input\": query})\n",
    "    result = qa_chain.invoke(query)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a489757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    if not os.path.exists(str(restaurant_faiss)):\n",
    "        create_faiss_index()\n",
    "\n",
    "    db = load_faiss_index()\n",
    "    while True:\n",
    "        query = input(\"레스토랑에 대해서 궁금한 점을 물어보세요 (종료하려면 'quit' 입력): \")\n",
    "        if query.lower() == \"quit\":\n",
    "            print(\"프로그램을 종료합니다.\")\n",
    "            break\n",
    "        answer = answer_question(db, query)\n",
    "        print(f\"답변: {answer}\\n\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffeb33c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: 네, 음직점에서는 다양한 아이들을 위한 키즈 메뉴를 제공하고 있습니다.\n",
      "\n",
      "답변: 음직점에서 유명한 요리는 무스케이크입니다.\n",
      "\n",
      "답변: 주변에는 무료 주차장이 마련되어 있어 편리하게 이용하실 수 있습니다.\n",
      "\n",
      "답변: 음직점에서 유명한 요리는 트러플 오일을 사용한 크림 파스타입니다.\n",
      "\n",
      "답변: 음직점에서는 신선하고 고품질의 식재료를 사용하며, 주로 지역에서 직접 공급받아 신선함을 유지하고 있습니다. 또한 지역에서 생산된 신선한 채소와 고기를 적극 활용합니다.\n",
      "\n",
      "답변: 음직점에서는 고품질 아라비카 원두를 사용하며, 에스프레소, 라떼, 아메리카노 등 다양한 커피 스타일과 특별한 시그니처 커피 메뉴를 제공합니다.\n",
      "\n",
      "답변: 네, 음직점에서는 다양한 시그니처 칵테일 프로그램과 칵테일 메뉴를 제공하고 있습니다.\n",
      "\n",
      "답변: 주어진 정보로는 정확한 답변을 드릴 수 없습니다.\n",
      "\n",
      "프로그램을 종료합니다.\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
